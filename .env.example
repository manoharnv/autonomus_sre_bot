# AI Model Configuration
MODEL=gpt-4o-mini
OPENAI_API_KEY=<deepseek-api-key>
OPENAI_API_BASE=https://api.deepseek.com
OPENAI_MODEL_NAME=deepseek/deepseek-chat

# Middleware.io Integration
MIDDLEWARE_API_KEY=<middleware-api-key>

# Atlassian Integration (JSM and MCP)
ATLASSIAN_CLOUD_ID=<your-atlassian-cloud-id>
ATLASSIAN_TOKEN=<your-atlassian-access-token>
ATLASSIAN_SERVICE_DESK_ID=<your-service-desk-id>
ATLASSIAN_REQUEST_TYPE_ID=<your-request-type-id>
ATLASSIAN_USER_ID=<your-atlassian-user-id>
ATLASSIAN_URL=https://yoursite.atlassian.net

# GitHub Integration (for MCP and self-healing crew)
GITHUB_TOKEN=<github-personal-access-token>
GITHUB_OWNER=<github-username-or-org>
GITHUB_REPO=<default-repository-name>

# Atlassian MCP Integration (for self-healing crew)
ATLASSIAN_TOKEN=<atlassian-api-token>
ATLASSIAN_CLOUD_ID=<atlassian-cloud-id>

# Kubernetes Integration (for self-healing crew)
KUBECONFIG=<path-to-kubeconfig-file>
KUBERNETES_NAMESPACE=production

# Self-Healing Crew Configuration
SELF_HEAL_POLLING_INTERVAL=300
SELF_HEAL_MAX_RETRIES=3
SELF_HEAL_TIMEOUT_MINUTES=30

# Langfuse Observability
LANGFUSE_PUBLIC_KEY=<langfuse-public-key>
LANGFUSE_SECRET_KEY=<langfuse-secret-key>
LANGFUSE_HOST=https://cloud.langfuse.com
OTEL_EXPORTER_OTLP_ENDPOINT=https://cloud.langfuse.com/api/public/otel

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE_PATH=logs/autonomous_sre.log